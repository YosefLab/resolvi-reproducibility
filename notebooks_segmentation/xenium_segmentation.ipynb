{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f42526c8",
   "metadata": {},
   "source": [
    "# Custom segmentation Xenium data\n",
    "\n",
    "We here provide commands to segment Xenium data into the different segmentations. Raw data can be accessed via Xenium. If data is not available there anymore, raw data can be requested with the corresponding authors.\n",
    "This notebook is not intended to be executed but rather is a collection of batch commands to execute segmentation and provides the commands used by us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327dbf17",
   "metadata": {},
   "source": [
    "## Baysor segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c802bb28-2d23-44b3-9754-26018d5ea7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e019e4d-16e9-494b-a56b-f21f74289406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tx_file = pd.read_csv('/external_data/other/Vizgen_redownload/HumanLiverCancerPatient1/detected_transcripts.csv', engine=\"pyarrow\")\n",
    "tx_file = pd.read_csv('transcripts.csv.gz', compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "341fa082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_file['cell_id'] = tx_file['cell_id'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8870024e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10261.238762, 7026.7352137)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_min, y_min = tx_file[['x_location', 'y_location']].min()\n",
    "x_max, y_max = tx_file[['x_location', 'y_location']].max()\n",
    "\n",
    "x_max - x_min, y_max - y_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cfcff2b-8768-4075-a404-33e293312e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tx_file['x_bin'] = pd.cut(tx_file['x_location'], bins=10, labels=list(np.arange(10)))\n",
    "tx_file['y_bin'] = pd.cut(tx_file['y_location'], bins=7, labels=list(np.arange(7)))\n",
    "\n",
    "# Group by the bins to get 49 rectangles\n",
    "tx_file['bin'] = tx_file['x_bin'].astype(str) + '_' + tx_file['y_bin'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c825f418-4fe8-4a95-8e05-1087812cc553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 28, 42, 49, 13, 20, 14, 21,  7, 27, 36, 29, 43, 50, 57, 56, 34,\n",
       "       64, 63,  8,  1,  0, 15, 22, 37, 30, 44, 51, 58,  2,  9, 65, 16, 23,\n",
       "       31, 38, 45, 52, 59, 66,  3, 10, 17, 32, 39, 24, 46, 53, 67, 60, 11,\n",
       "       18,  4, 25, 40, 47, 54, 33, 61, 68,  5, 12, 26, 19, 41, 48, 55, 62,\n",
       "        6, 69], dtype=int8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_file['fov_coarse'] = tx_file['bin'].astype(\"category\").cat.codes\n",
    "fov_list = tx_file['fov_coarse'].unique()\n",
    "fov_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9dc5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.mkdir('baysor_transcripts_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86ad3071-c174-4637-a3f8-525df3c299db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in tx_file['fov_coarse'].unique():\n",
    "    tx_file[tx_file['fov_coarse']==i].to_csv('baysor_transcripts_new/transcripts_xenium_' + str(i) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d3267fb-ef46-4e78-bd63-c43072b79c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35 28 42 49 13 20 14 21 7 27 36 29 43 50 57 56 34 64 63 8 1 0 15 22 37 30 44 51 58 2 9 65 16 23 31 38 45 52 59 66 3 10 17 32 39 24 46 53 67 60 11 18 4 25 40 47 54 33 61 68 5 12 26 19 41 48 55 62 6 69'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(fov_list.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39a5286",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "docker run -it -v /home/cane:/home/cane --rm vpetukhov/baysor:master\n",
    "\n",
    "cd /data/extra_files/xenium/Xenium_V1_FF_Mouse_Brain_Coronal_outs/baysor_transcripts_new/\n",
    "N=5\n",
    "(\n",
    "for VARIABLE in 35 28 42 49 13 20 14 21 7 27 36 29 43 50 57 56 34 64 63 8 1 0 15 22 37 30 44 51 58 2 9 65 16 23 31 38 45 52 59 66 3 10 17 32 39 24 46 53 67 60 11 18 4 25 40 47 54 33 61 68 5 12 26 19 41 48 55 62 6 69; do\n",
    "    ((i=i%N)); ((i++==0)) && wait\n",
    "    baysor run -x x_location -y y_location -z z_location --gene feature_name transcripts_xenium_$VARIABLE.csv :cell_id -o segmentation_fov_prior_$VARIABLE.csv -c config.toml --plot --save-polygons=geojson &  done\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e31afe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "json_files = glob('baysor_transcripts/*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b67b77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = f'baysor_transcripts/segmentation_fov_22_counts.tsv'\n",
    "df_transcript = pd.read_csv(csv_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c548511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import geojson\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# Get a list of all JSON files\n",
    "json_files = glob('baysor_transcripts/segmentation_fov_*_polygons.json')\n",
    "\n",
    "# Initialize an empty list to hold the GeoJSON data\n",
    "merged_data = []\n",
    "\n",
    "# Loop through each JSON file\n",
    "for file in json_files:\n",
    "    # Extract fov from the file name\n",
    "    fov = file.split('_')[3]\n",
    "\n",
    "    # Open the JSON file\n",
    "    with open(file, 'r') as f:\n",
    "        # Load the JSON data\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Load the corresponding CSV file\n",
    "    csv_file = f'baysor_transcripts/segmentation_fov_{fov}_cell_stats.csv'\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df['cell'] = df['cell'].astype(str)\n",
    "\n",
    "    # Convert the JSON data to GeoJSON and append to the list\n",
    "    for i, geometry in enumerate(data['geometries']):\n",
    "        print(i, len(data['geometries']))\n",
    "        # Add the 'cell' key with the corresponding value from the CSV file\n",
    "        geometry['properties'] = {'cell': fov + '_' + df['cell'].iloc[i]}\n",
    "        geojson_data = geojson.Polygon(geometry['coordinates'])\n",
    "        merged_data.append(geojson_data)\n",
    "\n",
    "# Create a GeoJSON GeometryCollection\n",
    "geometry_collection = geojson.GeometryCollection(merged_data)\n",
    "\n",
    "# Write the merged GeoJSON data to a new file\n",
    "with open('baysor_transcripts/merged.geojson', 'w') as f:\n",
    "    json.dump(geometry_collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ad3575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open the GeoJSON file\n",
    "with open('baysor-cell-polygons.geojson', 'r') as f:\n",
    "    # Load the GeoJSON data\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb13eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open the GeoJSON file\n",
    "with open('baysor_transcripts/merged.geojson', 'r') as f:\n",
    "    # Load the GeoJSON data\n",
    "    data_baysor = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Get a list of all CSV files\n",
    "csv_files = glob.glob('baysor_transcripts/segmentation_fov_*.csv')\n",
    "csv_files = [file for file in csv_files if \"_cell_stats.csv\" not in file]\n",
    "\n",
    "# Initialize an empty list to hold the dataframes\n",
    "df_list = []\n",
    "\n",
    "# Loop through each CSV file\n",
    "for file in csv_files:\n",
    "    # Load the data\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # Extract fov from the file name\n",
    "    fov = os.path.basename(file).split('_')[2].split('.')[0]\n",
    "\n",
    "    # Add a new column 'fov'\n",
    "    df['fov'] = fov\n",
    "\n",
    "    # Append the dataframe to the list\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "merged_df.to_csv('baysor_transcripts/merged_segmentation.csv')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc1d4789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2633505/1968872477.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_df_sub['cell'] = 'cell-' + merged_df_sub['cell'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "merged_df_sub = merged_df[['transcript_id', 'cell', 'is_noise', 'x', 'y', 'z']]\n",
    "merged_df_sub['cell'] = 'cell-' + merged_df_sub['cell'].astype(str)\n",
    "merged_df_sub.to_csv('baysor_transcripts/merged_segmentation_sub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef355556",
   "metadata": {},
   "source": [
    "## Xeniumranger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298cee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "export PATH=/data/extra_files/opts/xeniumranger-xenium2.0:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aa1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "xeniumranger import-segmentation \\\n",
    "    --id Xenium_V1_FF_Mouse_Brain_Coronal_baysor \\\n",
    "    --xenium-bundle /data/extra_files/xenium/Xenium_V1_FF_Mouse_Brain_Coronal_outs \\\n",
    "    --viz-polygons baysor-cell-polygons.geojson \\\n",
    "    --transcript-assignment baysor_transcripts/merged_segmentation.csv \\\n",
    "    --units microns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9abee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "xeniumranger resegment --id=Xenium_V1_FF_Mouse_Brain_Coronal_multimodal \\\n",
    "                       --xenium-bundle=/data/extra_files/xenium/Xenium_V1_FF_Mouse_Brain_Coronal_outs \\\n",
    "                       --expansion-distance=3 \\\n",
    "                       --localcores=20 \\\n",
    "                       --localmem=64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed272929",
   "metadata": {},
   "source": [
    "## ProSeg\n",
    "\n",
    "For ProSeg nucleus set folder to nucleus segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7174d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "proseg transcripts.csv.gz --xenium   \n",
    "proseg-to-baysor \\\n",
    "    transcript-metadata.csv.gz \\\n",
    "    cell-polygons.geojson.gz \\\n",
    "    --output-transcript-metadata baysor-transcript-metadata.csv \\\n",
    "    --output-cell-polygons baysor-cell-polygons.geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "xeniumranger import-segmentation \\\n",
    "    --id Xenium_V1_FF_Mouse_Brain_Coronal_proseg \\\n",
    "    --xenium-bundle /data/extra_files/xenium/Xenium_V1_FF_Mouse_Brain_Coronal_outs \\\n",
    "    --viz-polygons baysor-cell-polygons.geojson \\\n",
    "    --transcript-assignment baysor-transcript-metadata.csv \\\n",
    "    --units microns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resolvi_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
